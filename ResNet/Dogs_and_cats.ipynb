{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch    \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision as tv\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset2class(torch.utils.data.Dataset):\n",
    "    def __init__(self, path_dir1:str, path_dir2:str):\n",
    "        super().__init__()\n",
    "\n",
    "        self.path_dir1 = path_dir1\n",
    "        self.path_dir2 = path_dir2\n",
    "\n",
    "        self.dir1_list = sorted(os.listdir(path_dir1))\n",
    "        self.dir2_list = sorted(os.listdir(path_dir2))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dir1_list) + len(self.dir2_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx < len(self.dir1_list):\n",
    "            class_id = 0\n",
    "            img_path = os.path.join(self.path_dir1, self.dir1_list[idx])\n",
    "        else:\n",
    "            class_id = 1\n",
    "            idx -= len(self.dir1_list)\n",
    "            img_path = os.path.join(self.path_dir2, self.dir2_list[idx])\n",
    "\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        if img is None:\n",
    "            raise ValueError(f\"Изображение по пути {img_path} не может быть загружено.\")\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = img.astype(np.float32)\n",
    "        img = img/255.0\n",
    "\n",
    "        img = cv2.resize(img, (64, 64), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "        img = img.transpose((2, 0, 1))\n",
    "\n",
    "        t_img = torch.from_numpy(img)\n",
    "        t_class_id = torch.tensor(class_id)\n",
    "\n",
    "        return {'img' : t_img, 'label' :  t_class_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_catsdogs = Dataset2class('C:/Users/Administrator/Desktop/AAT/ResNet/dataset/training_set/cats',\n",
    "                             'C:/Users/Administrator/Desktop/AAT/ResNet/dataset/training_set/dogs')\n",
    "test_ds_catsdogs = Dataset2class('C:/Users/Administrator/Desktop/AAT/ResNet/dataset/test_set/cats',\n",
    "                             'C:/Users/Administrator/Desktop/AAT/ResNet/dataset/test_set/dogs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds_catsdogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_ds_catsdogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'img': tensor([[[0.8683, 0.8739, 0.8938,  ..., 0.9458, 0.9502, 0.9351],\n",
       "          [0.8741, 0.8685, 0.8898,  ..., 0.9358, 0.9659, 0.9438],\n",
       "          [0.8780, 0.8794, 0.8795,  ..., 0.9384, 0.9532, 0.9519],\n",
       "          ...,\n",
       "          [0.7955, 0.7723, 0.7345,  ..., 0.8576, 0.8383, 0.8471],\n",
       "          [0.7844, 0.7690, 0.7846,  ..., 0.8570, 0.8432, 0.8493],\n",
       "          [0.8279, 0.7893, 0.7976,  ..., 0.8518, 0.8464, 0.8472]],\n",
       " \n",
       "         [[0.8722, 0.8778, 0.8948,  ..., 0.9497, 0.9541, 0.9401],\n",
       "          [0.8780, 0.8725, 0.8927,  ..., 0.9397, 0.9698, 0.9500],\n",
       "          [0.8819, 0.8834, 0.8817,  ..., 0.9423, 0.9571, 0.9554],\n",
       "          ...,\n",
       "          [0.8069, 0.7462, 0.6685,  ..., 0.8693, 0.8370, 0.8316],\n",
       "          [0.8175, 0.7685, 0.7278,  ..., 0.8675, 0.8419, 0.8338],\n",
       "          [0.8313, 0.7670, 0.7201,  ..., 0.8626, 0.8435, 0.8311]],\n",
       " \n",
       "         [[0.8526, 0.8582, 0.8901,  ..., 0.9687, 0.9730, 0.9602],\n",
       "          [0.8584, 0.8529, 0.8769,  ..., 0.9590, 0.9875, 0.9697],\n",
       "          [0.8623, 0.8638, 0.8673,  ..., 0.9607, 0.9766, 0.9752],\n",
       "          ...,\n",
       "          [0.8170, 0.7642, 0.7022,  ..., 0.8677, 0.8216, 0.8158],\n",
       "          [0.8206, 0.7653, 0.7620,  ..., 0.8662, 0.8265, 0.8179],\n",
       "          [0.8461, 0.7612, 0.7549,  ..., 0.8640, 0.8381, 0.8164]]]),\n",
       " 'label': tensor(0)}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds_catsdogs[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_ds_catsdogs, shuffle=True, batch_size=batch_size,\n",
    "    num_workers=0, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_ds_catsdogs, shuffle=True, batch_size=batch_size,\n",
    "    num_workers=0, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'img': tensor([[[[1.0000, 1.0000, 0.9166,  ..., 0.9889, 0.9711, 0.9903],\n",
      "          [1.0000, 1.0000, 0.9166,  ..., 0.9844, 0.9707, 0.9926],\n",
      "          [1.0000, 1.0000, 0.9152,  ..., 0.9794, 0.9689, 0.9933],\n",
      "          ...,\n",
      "          [0.1692, 0.1699, 0.1824,  ..., 0.6593, 0.6550, 0.5009],\n",
      "          [0.1489, 0.1426, 0.3272,  ..., 0.6573, 0.6718, 0.4734],\n",
      "          [0.6855, 0.9146, 0.9258,  ..., 0.6733, 0.6749, 0.4317]],\n",
      "\n",
      "         [[0.9961, 0.9961, 0.9137,  ..., 0.9855, 0.9711, 0.9903],\n",
      "          [0.9961, 0.9961, 0.9137,  ..., 0.9810, 0.9707, 0.9926],\n",
      "          [0.9961, 0.9961, 0.9120,  ..., 0.9760, 0.9689, 0.9933],\n",
      "          ...,\n",
      "          [0.2211, 0.2106, 0.2144,  ..., 0.4815, 0.4522, 0.3622],\n",
      "          [0.1437, 0.1343, 0.3110,  ..., 0.4759, 0.4764, 0.3460],\n",
      "          [0.5955, 0.8192, 0.8266,  ..., 0.4870, 0.4811, 0.3100]],\n",
      "\n",
      "         [[0.9804, 0.9804, 0.8980,  ..., 0.9977, 0.9743, 0.9861],\n",
      "          [0.9804, 0.9804, 0.8980,  ..., 0.9945, 0.9739, 0.9885],\n",
      "          [0.9804, 0.9804, 0.8964,  ..., 0.9884, 0.9721, 0.9891],\n",
      "          ...,\n",
      "          [0.3327, 0.3224, 0.3231,  ..., 0.3687, 0.3335, 0.3012],\n",
      "          [0.2090, 0.1868, 0.3517,  ..., 0.3612, 0.3623, 0.2932],\n",
      "          [0.5862, 0.7950, 0.7821,  ..., 0.3719, 0.3714, 0.2696]]],\n",
      "\n",
      "\n",
      "        [[[0.4824, 0.5051, 0.5367,  ..., 0.5418, 0.5423, 0.5376],\n",
      "          [0.4761, 0.5049, 0.5350,  ..., 0.5435, 0.5429, 0.5413],\n",
      "          [0.4784, 0.5058, 0.5339,  ..., 0.5467, 0.5510, 0.5488],\n",
      "          ...,\n",
      "          [0.4760, 0.4810, 0.4760,  ..., 0.3575, 0.3541, 0.3983],\n",
      "          [0.4759, 0.4860, 0.4828,  ..., 0.3512, 0.3467, 0.3897],\n",
      "          [0.4701, 0.4766, 0.4859,  ..., 0.3466, 0.3419, 0.3789]],\n",
      "\n",
      "         [[0.4471, 0.4698, 0.5014,  ..., 0.5104, 0.5109, 0.5062],\n",
      "          [0.4408, 0.4696, 0.4997,  ..., 0.5121, 0.5115, 0.5099],\n",
      "          [0.4431, 0.4705, 0.4990,  ..., 0.5182, 0.5196, 0.5174],\n",
      "          ...,\n",
      "          [0.4407, 0.4457, 0.4407,  ..., 0.3332, 0.3385, 0.3768],\n",
      "          [0.4406, 0.4507, 0.4475,  ..., 0.3267, 0.3310, 0.3680],\n",
      "          [0.4336, 0.4413, 0.4506,  ..., 0.3197, 0.3210, 0.3538]],\n",
      "\n",
      "         [[0.4589, 0.4816, 0.5132,  ..., 0.5693, 0.5697, 0.5650],\n",
      "          [0.4526, 0.4813, 0.5114,  ..., 0.5709, 0.5704, 0.5688],\n",
      "          [0.4522, 0.4795, 0.5071,  ..., 0.5761, 0.5785, 0.5762],\n",
      "          ...,\n",
      "          [0.4524, 0.4574, 0.4518,  ..., 0.3898, 0.3933, 0.4331],\n",
      "          [0.4523, 0.4625, 0.4587,  ..., 0.3833, 0.3859, 0.4244],\n",
      "          [0.4528, 0.4533, 0.4617,  ..., 0.3770, 0.3768, 0.4108]]],\n",
      "\n",
      "\n",
      "        [[[0.2314, 0.2314, 0.2314,  ..., 0.2577, 0.2674, 0.2595],\n",
      "          [0.2314, 0.2314, 0.2314,  ..., 0.2538, 0.2433, 0.2480],\n",
      "          [0.2314, 0.2314, 0.2314,  ..., 0.2393, 0.2412, 0.2500],\n",
      "          ...,\n",
      "          [0.3143, 0.3870, 0.3764,  ..., 0.3133, 0.3179, 0.3506],\n",
      "          [0.3222, 0.3641, 0.3869,  ..., 0.3683, 0.3431, 0.3474],\n",
      "          [0.3255, 0.3385, 0.3703,  ..., 0.4122, 0.3398, 0.3442]],\n",
      "\n",
      "         [[0.2510, 0.2510, 0.2510,  ..., 0.2462, 0.2560, 0.2516],\n",
      "          [0.2510, 0.2510, 0.2510,  ..., 0.2451, 0.2341, 0.2402],\n",
      "          [0.2510, 0.2510, 0.2510,  ..., 0.2343, 0.2345, 0.2422],\n",
      "          ...,\n",
      "          [0.3336, 0.3824, 0.3569,  ..., 0.2720, 0.2754, 0.3058],\n",
      "          [0.3384, 0.3593, 0.3702,  ..., 0.3299, 0.3042, 0.3061],\n",
      "          [0.3371, 0.3302, 0.3590,  ..., 0.3849, 0.3112, 0.3116]],\n",
      "\n",
      "         [[0.2275, 0.2275, 0.2275,  ..., 0.3169, 0.3275, 0.3051],\n",
      "          [0.2275, 0.2275, 0.2275,  ..., 0.3013, 0.2929, 0.2920],\n",
      "          [0.2275, 0.2275, 0.2275,  ..., 0.2658, 0.2770, 0.2875],\n",
      "          ...,\n",
      "          [0.2353, 0.2874, 0.2277,  ..., 0.2764, 0.2851, 0.3337],\n",
      "          [0.2343, 0.2619, 0.2435,  ..., 0.3388, 0.3162, 0.3351],\n",
      "          [0.2343, 0.2328, 0.2366,  ..., 0.4006, 0.3311, 0.3476]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.7108, 0.6946, 0.6737,  ..., 0.1925, 0.2061, 0.2239],\n",
      "          [0.7113, 0.6953, 0.6666,  ..., 0.2403, 0.2325, 0.2342],\n",
      "          [0.4767, 0.5159, 0.5305,  ..., 0.2463, 0.2399, 0.2437],\n",
      "          ...,\n",
      "          [0.1461, 0.2811, 0.5202,  ..., 0.1241, 0.0965, 0.0971],\n",
      "          [0.1411, 0.4371, 0.5790,  ..., 0.1708, 0.1225, 0.1017],\n",
      "          [0.1037, 0.3142, 0.4179,  ..., 0.1215, 0.1079, 0.0857]],\n",
      "\n",
      "         [[0.7304, 0.7142, 0.6933,  ..., 0.2186, 0.2323, 0.2500],\n",
      "          [0.7303, 0.7148, 0.6862,  ..., 0.2453, 0.2373, 0.2391],\n",
      "          [0.4570, 0.5150, 0.5386,  ..., 0.2482, 0.2418, 0.2455],\n",
      "          ...,\n",
      "          [0.1673, 0.2852, 0.5078,  ..., 0.1443, 0.1198, 0.1270],\n",
      "          [0.1882, 0.4510, 0.5686,  ..., 0.1910, 0.1494, 0.1423],\n",
      "          [0.1222, 0.2643, 0.3547,  ..., 0.1380, 0.1289, 0.1158]],\n",
      "\n",
      "         [[0.7068, 0.6907, 0.6698,  ..., 0.1803, 0.1939, 0.2117],\n",
      "          [0.7053, 0.6905, 0.6624,  ..., 0.2321, 0.2242, 0.2259],\n",
      "          [0.3940, 0.4628, 0.4838,  ..., 0.2299, 0.2235, 0.2273],\n",
      "          ...,\n",
      "          [0.1196, 0.2770, 0.4924,  ..., 0.1188, 0.0928, 0.0974],\n",
      "          [0.1631, 0.4333, 0.5498,  ..., 0.1717, 0.1273, 0.1156],\n",
      "          [0.1332, 0.2719, 0.3519,  ..., 0.1387, 0.1274, 0.1110]]],\n",
      "\n",
      "\n",
      "        [[[0.2824, 0.2824, 0.2824,  ..., 0.4196, 0.4196, 0.4196],\n",
      "          [0.2824, 0.2837, 0.2852,  ..., 0.4223, 0.4204, 0.4196],\n",
      "          [0.2824, 0.2879, 0.2941,  ..., 0.4306, 0.4229, 0.4196],\n",
      "          ...,\n",
      "          [0.3040, 0.3005, 0.2962,  ..., 0.5779, 0.5708, 0.5652],\n",
      "          [0.3362, 0.3474, 0.3461,  ..., 0.5866, 0.5849, 0.5827],\n",
      "          [0.3893, 0.3982, 0.4081,  ..., 0.6137, 0.6080, 0.6096]],\n",
      "\n",
      "         [[0.2196, 0.2196, 0.2196,  ..., 0.3725, 0.3725, 0.3725],\n",
      "          [0.2196, 0.2209, 0.2224,  ..., 0.3752, 0.3733, 0.3725],\n",
      "          [0.2196, 0.2252, 0.2314,  ..., 0.3836, 0.3759, 0.3725],\n",
      "          ...,\n",
      "          [0.2658, 0.2623, 0.2580,  ..., 0.5622, 0.5551, 0.5495],\n",
      "          [0.3091, 0.3202, 0.3189,  ..., 0.5709, 0.5692, 0.5671],\n",
      "          [0.3632, 0.3709, 0.3794,  ..., 0.5836, 0.5791, 0.5802]],\n",
      "\n",
      "         [[0.1216, 0.1216, 0.1216,  ..., 0.2706, 0.2706, 0.2706],\n",
      "          [0.1216, 0.1229, 0.1244,  ..., 0.2732, 0.2714, 0.2706],\n",
      "          [0.1216, 0.1271, 0.1333,  ..., 0.2816, 0.2739, 0.2706],\n",
      "          ...,\n",
      "          [0.1890, 0.1855, 0.1812,  ..., 0.5258, 0.5198, 0.5142],\n",
      "          [0.2392, 0.2504, 0.2491,  ..., 0.5345, 0.5339, 0.5318],\n",
      "          [0.2946, 0.3110, 0.3275,  ..., 0.5536, 0.5489, 0.5502]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 1.0000, 1.0000,  ..., 0.9984, 0.9966, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 0.9984, 0.9963, 0.9996],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 0.9984, 0.9964, 0.9992],\n",
      "          ...,\n",
      "          [0.1079, 0.1070, 0.1122,  ..., 0.3979, 0.3820, 0.3671],\n",
      "          [0.0821, 0.0800, 0.0789,  ..., 0.3993, 0.3777, 0.3596],\n",
      "          [0.0614, 0.0528, 0.0553,  ..., 0.3789, 0.3661, 0.3439]],\n",
      "\n",
      "         [[0.9451, 0.9451, 0.9451,  ..., 0.9467, 0.9495, 0.9529],\n",
      "          [0.9451, 0.9451, 0.9451,  ..., 0.9467, 0.9493, 0.9529],\n",
      "          [0.9451, 0.9451, 0.9451,  ..., 0.9467, 0.9494, 0.9529],\n",
      "          ...,\n",
      "          [0.1340, 0.1331, 0.1390,  ..., 0.4215, 0.4055, 0.3906],\n",
      "          [0.1068, 0.1047, 0.1048,  ..., 0.4229, 0.4012, 0.3831],\n",
      "          [0.0721, 0.0635, 0.0677,  ..., 0.4025, 0.3897, 0.3674]],\n",
      "\n",
      "         [[0.9961, 0.9961, 0.9978,  ..., 0.9984, 0.9966, 1.0000],\n",
      "          [0.9961, 0.9961, 0.9978,  ..., 0.9984, 0.9963, 0.9996],\n",
      "          [0.9961, 0.9961, 0.9978,  ..., 0.9984, 0.9964, 0.9992],\n",
      "          ...,\n",
      "          [0.1760, 0.1751, 0.1773,  ..., 0.3823, 0.3663, 0.3514],\n",
      "          [0.1497, 0.1476, 0.1392,  ..., 0.3837, 0.3620, 0.3439],\n",
      "          [0.1065, 0.0979, 0.0922,  ..., 0.3633, 0.3504, 0.3282]]]]), 'label': tensor([0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1])}\n"
     ]
    }
   ],
   "source": [
    "for sample in train_loader:\n",
    "    print(sample)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.act = nn.LeakyReLU(0.2)\n",
    "        self.maxpool = nn.MaxPool2d(2, 2)\n",
    "        self.conv0 = nn.Conv2d(3, 32, 3, stride=1, padding=0)\n",
    "        self.conv1 = nn.Conv2d(32, 32, 3, stride=1, padding=0)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, stride=1, padding=0)\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3, stride=1, padding=0)\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3, stride=1, padding=0)\n",
    "\n",
    "        self.adaptivepool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear1 = nn.Linear(64, 10)\n",
    "        self.linear2 = nn.Linear(10, 2)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv0(x)\n",
    "        out = self.act(out)\n",
    "        out = self.maxpool(out)\n",
    "\n",
    "        out = self.conv1(out)\n",
    "        out = self.act(out)\n",
    "        out = self.maxpool(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.act(out)\n",
    "        out = self.maxpool(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.act(out)\n",
    "\n",
    "        out = self.adaptivepool(out)\n",
    "        out = self.flatten(out)\n",
    "        out = self.linear1(out)\n",
    "        out = self.act(out)\n",
    "        out = self.linear2(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parametrs(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (act): LeakyReLU(negative_slope=0.2)\n",
       "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (adaptivepool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear1): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (linear2): Linear(in_features=10, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103168"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parametrs(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred, label):\n",
    "    answer = F.softmax(pred.detach()).numpy().argmax(1) == label.numpy().argmax(1)\n",
    "    # print(answer)\n",
    "    # print(answer.sum())\n",
    "    return answer.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_28488\\3440098169.py:2: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  answer = F.softmax(pred.detach()).numpy().argmax(1) == label.numpy().argmax(1)\n",
      "loss: 0.7066\taccuracy: 0.500: 100%|██████████| 500/500 [01:08<00:00,  7.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6890115146636963\n",
      "0.534875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.6258\taccuracy: 0.625: 100%|██████████| 500/500 [00:42<00:00, 11.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6635780782103539\n",
      "0.597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.7183\taccuracy: 0.625: 100%|██████████| 500/500 [00:43<00:00, 11.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6081633687615394\n",
      "0.67075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.4658\taccuracy: 0.688: 100%|██████████| 500/500 [00:44<00:00, 11.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5472135010659694\n",
      "0.7235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.6312\taccuracy: 0.625: 100%|██████████| 500/500 [00:42<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5024665699601173\n",
      "0.7525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.7542\taccuracy: 0.562: 100%|██████████| 500/500 [00:43<00:00, 11.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46825337007641793\n",
      "0.7805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.2812\taccuracy: 0.875: 100%|██████████| 500/500 [00:42<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42599266244471073\n",
      "0.802625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.4127\taccuracy: 0.875: 100%|██████████| 500/500 [00:43<00:00, 11.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39575936684012414\n",
      "0.81575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.2710\taccuracy: 0.812: 100%|██████████| 500/500 [00:42<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36625798599421977\n",
      "0.83775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.2095\taccuracy: 0.938: 100%|██████████| 500/500 [00:41<00:00, 12.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3372217895835638\n",
      "0.8475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    loss_val = 0\n",
    "    acc_val = 0\n",
    "    for sample in (pbar := tqdm(train_loader)):\n",
    "        img, label = sample['img'], sample['label']\n",
    "        optimizer.zero_grad()\n",
    "        label = F.one_hot(label, 2).float()\n",
    "        pred = model(img)\n",
    "\n",
    "        loss = loss_fn(pred, label)\n",
    "        loss.backward()\n",
    "        loss_item = loss.item()\n",
    "        loss_val += loss_item\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        acc_current = accuracy(pred, label)\n",
    "        acc_val += acc_current\n",
    "\n",
    "        pbar.set_description(f'loss: {loss_item:.4f}\\taccuracy: {acc_current:.3f}')\n",
    "    print(loss_val/len(train_loader))\n",
    "    print(acc_val/len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/125 [00:00<?, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_28488\\3440098169.py:2: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  answer = F.softmax(pred.detach()).numpy().argmax(1) == label.numpy().argmax(1)\n",
      "loss: 0.2563\taccuracy: 0.812: 100%|██████████| 125/125 [00:21<00:00,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4120151214003563\n",
      "0.817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "loss_val = 0\n",
    "acc_val = 0\n",
    "for sample in (pbar := tqdm(test_loader)):\n",
    "    with torch.no_grad():\n",
    "        img, label = sample['img'], sample['label']\n",
    "        label = F.one_hot(label, 2).float()\n",
    "        pred = model(img)\n",
    "\n",
    "        loss = loss_fn(pred, label)\n",
    "        loss_item = loss.item()\n",
    "        loss_val += loss_item\n",
    "\n",
    "        acc_current = accuracy(pred, label)\n",
    "        acc_val += acc_current\n",
    "\n",
    "    pbar.set_description(f'loss: {loss_item:.4f}\\taccuracy: {acc_current:.3f}')\n",
    "print(loss_val/len(test_loader))\n",
    "print(acc_val/len(test_loader))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
